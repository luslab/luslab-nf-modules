/*
 * -------------------------------------------------
 *  Nextflow config file
 * -------------------------------------------------
 * Default config options for luslab.
 */

// Define DSL2
nextflow.preview.dsl=2

 // Include utils module
//include check_max from './tools/luslab_util/main.nf'

// Main parameters
params {
  // General
  append_outdir = true // Append timestamp to results folder
  outdir = './results' // Results output directory location
  tracedir = "${params.outdir}/_pipeline_info" // Trace directy default location

  // Logging options
  verbose = false
  monochrome_logs = false

  // Computing options - defaults only
  max_memory = 8.GB
  max_cpus = 4
  max_time = 240.h
}

// Append timestamp to files in results folder
if (params.append_outdir) {
   Date date = new Date()
   String timestamp = date.format("yyMMdd_HHmmss")
   params.outdir += "/res_" + timestamp
   params.tracedir = "${params.outdir}/_pipeline_info"
}

// Static details about the pipeline
manifest {
  name = 'pipeline-name'
  author = 'Luscombe Lab'
  homePage = 'pipeline-homepage'
  description = 'pipeline-description'
  nextflowVersion = '>=20.07.1'
  version = '0.1'
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Avoid this error:
// WARNING: Your kernel does not support swap limit capabilities or the cgroup is not mounted. 
// Memory limited without swap.
// Testing this in nf-core after discussion here https://github.com/nf-core/tools/pull/351, 
//once this is established and works well, nextflow might implement this behavior as new default.
docker.runOptions = '-u \$(id -u):\$(id -g)'

// Enable by default nextflow tracing and place in trace dir location
timeline {
  enabled = true
  file = "${params.tracedir}/execution_timeline.html"
}
report {
  enabled = true
  file = "${params.tracedir}/execution_report.html"
}
trace {
  enabled = true
  file = "${params.tracedir}/execution_trace.txt"
}
dag {
  enabled = true
  file = "${params.tracedir}/pipeline_dag.svg"
}

// Create process scaling defaults for running on a cluster
process {
  // Memory and time increases with the number of retrys
  cpus = { check_max( 2, 'cpus' ) }
  memory = { check_max( 4.GB * task.attempt, 'memory' ) }
  time = { check_max( 2.h * task.attempt, 'time' ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'terminate' }
  maxRetries = 1
  maxErrors = '-1'
}

// Create run profiles
profiles {
  docker { docker.enabled = true }
  singularity { singularity.enabled = true
                singularity.autoMounts = true
                docker.enabled = false }
  crick { includeConfig 'crick.config' }
}

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
        return params.max_memory as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
        return params.max_time as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, params.max_cpus as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
      return obj
    }
  }
}