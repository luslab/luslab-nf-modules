/*
 * Specific config for the Francis Crick Institute CAMP computing cluster
 */

// CAMP runs on a singularity container env
singularity {
  enabled = true
  autoMounts = true
}
docker.enabled = false

// Path to shared luslab singularity cache
// NOTE: this cannot be overriden in downstream config so it cannot be set here
//singularity.cacheDir = '/camp/lab/luscomben/home/shared/singularity'

// Crick specific computing max resource levels
params {
  // Max CPU queue parameters
  max_cpus = 32
  max_gpus = 0
  max_memory = 224.GB
  max_time = 72.h

  // Max hmem queue parameters
  max_hmem_cpus = 96
  max_hmem_gpus = 0
  max_hmem_memory = 1500.GB
  max_hmem_time = 72.h

  // Max gpu queue parameters
  max_gpu_cpus = 40
  max_gpu_gpus = 4
  max_gpu_memory = 768.GB
  max_gpu_time = 72.h
}

/*Selectors priority
When mixing generic process configuration and selectors the following priority rules are applied (from lower to higher):

1. Process generic configuration.
2. Process specific directive defined in the workflow script.
3. withLabel selector definition.
4. withName selector definition.
*/
process {
  executor = 'slurm'
  queue = 'cpu'

  // Time increases with the number of retrys
  cpus = { check_max( 1, 'cpus' ) }
  memory = { check_max( 4.GB, 'memory' ) }
  time = { check_max( 2.h * task.attempt, 'time' ) }

  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'terminate' }
  maxRetries = 1
  maxErrors = '-1'

  // Min - mn
  // Low - l
  // Medium - m
  // High - h
  // Max - mx

  /***** CPU queue labels ******/
  withLabel: mn_cpu {
        cpus = { check_max( 1, 'cpus' ) }
        memory = { check_max( 4.GB, 'memory' ) }
        queue = 'cpu'
  }
  withLabel: l_cpu {
        cpus = { check_max( 4, 'cpus' ) }
        memory = { check_max( 16.GB, 'memory' ) }
        queue = 'cpu'
  }
  withLabel: m_cpu {
        cpus = { check_max( 8, 'cpus' ) }
        memory = { check_max( 32.GB, 'memory' ) }
        queue = 'cpu'
  }
  withLabel: h_cpu {
        cpus = { check_max( 16, 'cpus' ) }
        memory = { check_max( 64.GB, 'memory' ) }
        queue = 'cpu'
  }
  withLabel: mx_cpu {
        cpus = { check_max( 32, 'cpus' ) }
        memory = { check_max( 128.GB, 'memory' ) }
        queue = 'cpu'
  }
  
  /***** hmem queue labels ******/
  withLabel: mn_hmem {
        cpus = { check_custom_max( 1, 'cpus', params.max_hmem_cpus ) }
        memory = { check_custom_max( 300.GB, 'memory', params.max_hmem_memory ) }
        queue = 'hmem'
  }
  withLabel: l_hmem {
        cpus = { check_custom_max( 8, 'cpus', params.max_hmem_cpus ) }
        memory = { check_custom_max( 500.GB, 'memory', params.max_hmem_memory ) }
        queue = 'hmem'
  }
  withLabel: m_hmem {
        cpus = { check_custom_max( 16, 'cpus', params.max_hmem_cpus ) }
        memory = { check_custom_max( 750.GB, 'memory', params.max_hmem_memory ) }
        queue = 'hmem'
  }
  withLabel: h_hmem {
        cpus = { check_custom_max( 32, 'cpus', params.max_hmem_cpus ) }
        memory = { check_custom_max( 1000.GB, 'memory', params.max_hmem_memory ) }
        queue = 'hmem'
  }
  withLabel: mx_hmem {
        cpus = { check_custom_max( 32, 'cpus', params.max_hmem_cpus ) }
        memory = { check_custom_max( 1500.GB, 'memory', params.max_hmem_memory ) }
        queue = 'hmem'
  }

    // if(params.num_gpus == 0) {
    //   queue = 'cpu'
    // }
    // else {
    //   // Cluster options for GPU enabled instances
    //   queue = 'gpu'
    //   clusterOptions = "--gres=gpu:" + check_max( params.num_gpus, 'gpus' )

    //   // Container options for GPU enabled instances
    //   singularity.runOptions = '--nv'
    // }
}

def check_custom_max(obj, type, max) {
  if (type == 'memory') {
    try {
      if (obj.compareTo(max as nextflow.util.MemoryUnit) == 1)
        return max as nextflow.util.MemoryUnit
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max memory '${max}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'time') {
    try {
      if (obj.compareTo(max as nextflow.util.Duration) == 1)
        return max as nextflow.util.Duration
      else
        return obj
    } catch (all) {
      println "   ### ERROR ###   Max time '${max}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'cpus') {
    try {
      return Math.min( obj, max as int )
    } catch (all) {
      println "   ### ERROR ###   Max cpus '${max}' is not valid! Using default value: $obj"
      return obj
    }
  } else if (type == 'gpus') {
    try {
      return Math.min( obj, max as int )
    } catch (all) {
      println "   ### ERROR ###   Max gpus '${max}' is not valid! Using default value: $obj"
      return obj as String
    }
  }
}